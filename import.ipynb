{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data (XMP, EXIF and Images) to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import struct, base64, zlib, binascii, CppHeaderParser, re, collections, logging, sys, itertools, glob, json, \\\n",
    "    pyexiv2, fractions, os, numpy, pandas\n",
    "from wand.image import Image\n",
    "from wand.display import display\n",
    "try:\n",
    "    from cStringIO import StringIO\n",
    "except ImportError:\n",
    "    from StringIO import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "log_formatter = logging.Formatter('%(asctime)-15s %(levelname)10s %(message)s')\n",
    "stderr_handler = logging.StreamHandler(sys.stderr)\n",
    "stderr_handler.setFormatter(log_formatter)\n",
    "stderr_handler.setLevel(logging.DEBUG)\n",
    "file_handler = logging.FileHandler('import.log')\n",
    "file_handler.setFormatter(log_formatter)\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "logger.handlers = []\n",
    "logger.addHandler(stderr_handler)\n",
    "logger.addHandler(file_handler)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect data structures that we need to parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STRUCTS = {\n",
    "           'dt_iop_tonecurve_node_t' : 'ff',\n",
    "           'dt_iop_vector_2d_t' : 'ff'\n",
    "           }\n",
    "ENUMS = frozenset({\n",
    "                   'dt_image_orientation_t',\n",
    "                   'dt_gaussian_order_t',\n",
    "                   'dt_iop_shadhi_algo_t',\n",
    "                   'dt_iop_lowpass_algo_t',\n",
    "                   'dt_colorspaces_color_profile_type_t',\n",
    "                   'dt_iop_colormapping_flags_t',\n",
    "                   'dt_iop_ashift_mode_t',\n",
    "                   'dt_iop_ashift_crop_t',\n",
    "                   'dt_iop_tonecurve_node_t',\n",
    "                   'dt_iop_colortransfer_flag_t',\n",
    "                   'dt_colorspaces_color_mode_t',\n",
    "                   'dt_iop_dither_type_t',\n",
    "                   'dt_iop_watermark_base_scale_t',\n",
    "                   'dt_iop_defringe_mode_t',\n",
    "                   'dt_iop_colorzones_channel_t',\n",
    "                   'dt_iop_denoiseprofile_mode_t',\n",
    "                   'dt_iop_highlights_mode_t',\n",
    "                   '_dt_iop_grain_channel_t',\n",
    "                   'dt_iop_levels_mode_t'\n",
    "                   })\n",
    "ENUM_FMT = 'I'\n",
    "DEFAULT_FMT = 'I'\n",
    "TYPE_RE = (\n",
    "    (re.compile(r'unsigned char|uchar|uint8'), 'B'),\n",
    "    (re.compile(r'char|int8'), 'c'),\n",
    "    (re.compile(r'bool'), '?'),\n",
    "    (re.compile(r'unsigned short|ushort|uint16'), 'H'),\n",
    "    (re.compile(r'short|int16'), 'h'),\n",
    "    (re.compile(r'uint32'), 'I'),\n",
    "    (re.compile(r'int32'), 'i'),\n",
    "    (re.compile(r'unsigned long long|uint64'), 'Q'),\n",
    "    (re.compile(r'long long|int64'), 'q'),\n",
    "    (re.compile(r'unsigned long|ulong|uint'), 'Q'),\n",
    "    (re.compile(r'long|int'), 'q'),\n",
    "    (re.compile(r'float'), 'f'),\n",
    "    (re.compile(r'double'), 'd'),\n",
    "    (re.compile(r'char\\[]'), 's')\n",
    ")\n",
    "CONSTANTS = {\n",
    "             'DT_IOP_COLOR_ICC_LEN' : 100,\n",
    "             'HISTN' : 1 << 11,\n",
    "             'MAXN' : 5,\n",
    "             'CHANNEL_SIZE' : 7,\n",
    "             'MAX_ZONE_SYSTEM_SIZE' : 24,\n",
    "             'DT_IOP_LOWLIGHT_LUT_RES' : 0x10000,\n",
    "             'atrous_none' : 5\n",
    "             }\n",
    "ARRAY_SIZES = {\n",
    "               'dt_iop_zonesystem_params_t' : { 'zone' : 25 },\n",
    "               'dt_iop_colorchecker_data_t' : {\n",
    "                                               'source_Lab' : 3 * 49,\n",
    "                                               'coeff_L' : 49 + 4,\n",
    "                                               'coeff_a' : 49 + 4,\n",
    "                                               'coeff_b' : 49 + 4\n",
    "                                               },\n",
    "               'dt_iop_colorbalance_data_t' : { 'lift' : CONSTANTS['CHANNEL_SIZE'] }\n",
    "}\n",
    "def build_typedef(c_def_string, align = '='):\n",
    "    parsed = CppHeaderParser.CppHeader(c_def_string, argType = 'string')\n",
    "    definition = next(iter(parsed.classes.values()))\n",
    "    fmt = align\n",
    "    names = []\n",
    "    sizes = []\n",
    "    for field in definition['properties']['public']:\n",
    "        names.append(field['name'])\n",
    "\n",
    "        fmt_factor = 1\n",
    "        if int(field['array']):\n",
    "            known_size = ARRAY_SIZES.get(definition['name'], {}).get(field['name'], None)\n",
    "            if not known_size is None:\n",
    "                fmt_factor = known_size\n",
    "            else:\n",
    "                if 'array_size' in field:\n",
    "                    try:\n",
    "                        if isinstance(field['array_size'], str):\n",
    "                            fmt_factor = int(field['array_size'], 0)\n",
    "                        else:\n",
    "                            fmt_factor = int(field['array_size'])\n",
    "                    except ValueError:\n",
    "                        if field['array_size'] in CONSTANTS:\n",
    "                            fmt_factor = CONSTANTS[field['array_size']]\n",
    "                        else:\n",
    "                            logger.warning('%s parse error: %s is array, could not parse size %s' % (definition['name'],\n",
    "                                                                                                     field['name'],\n",
    "                                                                                                     field['array_size']))\n",
    "                else:\n",
    "                    logger.warning('%s parse error: %s is array, but size is unknown' % (definition['name'],\n",
    "                                                                                         field['name']))\n",
    "        sizes.append(fmt_factor)\n",
    "\n",
    "        field_fmt = None\n",
    "        ftype = field['type']\n",
    "        if ftype in STRUCTS:\n",
    "            field_fmt = STRUCTS[ftype]\n",
    "        elif ftype in ENUMS:\n",
    "            field_fmt = ENUM_FMT\n",
    "        else:\n",
    "            for regex, t in TYPE_RE:\n",
    "                if regex.search(ftype):\n",
    "                    field_fmt = t\n",
    "                    break\n",
    "        if field_fmt is None:\n",
    "            logger.warning('%s parse error: could not determine format of field %s (type %s)' % (definition['name'],\n",
    "                                                                                                 field['name'],\n",
    "                                                                                                 ftype))\n",
    "            field_fmt = DEFAULT_FMT\n",
    "        fmt += field_fmt*fmt_factor\n",
    "    return (fmt, names, sizes)\n",
    "\n",
    "\n",
    "STRUCT_SUFFIXES = ('data', 'params')\n",
    "def try_extract_filter_info(filename, filter_name = None):\n",
    "    logger.info('Extracting filter info from %s' % filename)\n",
    "    if filter_name is None:\n",
    "        filter_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "    with open(filename, 'r') as f:\n",
    "        content = f.read()\n",
    "    for suffix in STRUCT_SUFFIXES:\n",
    "        data_def = re.search(r'typedef struct dt_iop_%s_%s_t.*?dt_iop_%s_%s_t;' % (filter_name,\n",
    "                                                                                   suffix,\n",
    "                                                                                   filter_name,\n",
    "                                                                                   suffix),\n",
    "                             content,\n",
    "                             re.DOTALL)\n",
    "        if data_def:\n",
    "            return filter_name, build_typedef(data_def.group(0))\n",
    "    return None\n",
    "\n",
    "def build_filter_info_table(darktable_src_dir):\n",
    "    plugins_dir = os.path.join(darktable_src_dir, 'src', 'iop')\n",
    "    return { info[0] : info[1]\n",
    "            for info\n",
    "            in (try_extract_filter_info(os.path.join(plugins_dir, f))\n",
    "                for f\n",
    "                in os.listdir(plugins_dir))\n",
    "            if not info is None\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filters_info = build_filter_info_table('/home/windj/projects/thirdparty/darktable')\n",
    "# with open('data/filters.js', 'w') as f:\n",
    "#     json.dump(filters_info, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_struct(data, fmt, names, sizes):\n",
    "    if data.startswith('gz'):\n",
    "        data = data[4:]\n",
    "        data = base64.decodestring(data)\n",
    "        data = zlib.decompress(data)\n",
    "    else:\n",
    "        data = binascii.unhexlify(data)\n",
    "    needed_size = struct.calcsize(fmt)\n",
    "    if len(data) != needed_size:\n",
    "        logger.error('parse_struct: %d bytes expected, %d bytes got' % (needed_size, len(data)))\n",
    "        return None\n",
    "    data = struct.unpack(fmt, data)\n",
    "    result = {}\n",
    "    i = 0\n",
    "    for name, size in itertools.izip(names, sizes):\n",
    "        if size == 1:\n",
    "            result[name] = data[i]\n",
    "        else:\n",
    "            result[name] = data[i:i + size]\n",
    "        i += size\n",
    "    return result\n",
    "\n",
    "class StructParser(object):\n",
    "    def __init__(self, filter_info):\n",
    "        self.filter_info = filter_info\n",
    "\n",
    "    def __call__(self, data):\n",
    "        return parse_struct(data, *self.filter_info)\n",
    "\n",
    "\n",
    "class JointParser(object):\n",
    "    def __init__(self, filters_info):\n",
    "        self.parsers = { name : StructParser(info)\n",
    "                        for name, info\n",
    "                        in filters_info.viewitems() }\n",
    "    \n",
    "    def __call__(self, filter_name_data_pairs):\n",
    "        result = {}\n",
    "        for name, data in filter_name_data_pairs:\n",
    "            parser = self.parsers.get(name)\n",
    "            result['%s.ENABLED' % name] = 1\n",
    "            if parser is None:\n",
    "                logger.warning('Unknown filter %s!' % name)\n",
    "                continue\n",
    "            parse_res = parser(data)\n",
    "            if parse_res is None:\n",
    "                logger.warning('Could not parse %s data %s' % (name, data))\n",
    "                continue\n",
    "            for k, v in parse_res.viewitems():\n",
    "                result['%s.%s' % (name, k)] = v\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xmp_data(filename, filter_data_parser):\n",
    "    metadata = pyexiv2.ImageMetadata(filename)\n",
    "    metadata.read()\n",
    "    filters_data = ((name, data)\n",
    "                    for name, data, enabled\n",
    "                    in itertools.izip(metadata['Xmp.darktable.history_operation'].value,\n",
    "                                      metadata['Xmp.darktable.history_params'].value,\n",
    "                                      metadata['Xmp.darktable.history_enabled'].value)\n",
    "                    if enabled)\n",
    "    result = {}\n",
    "    try:\n",
    "        result['rating'] = metadata['Exif.Image.Rating'].value\n",
    "    except KeyError:\n",
    "        pass\n",
    "    result.update(filter_data_parser(filters_data))\n",
    "    return result\n",
    "\n",
    "IGNORED_IMAGE_METADATA = frozenset({\n",
    "                                    'Exif.Canon.AFInfo',\n",
    "                                    'Exif.Canon.CameraInfo',\n",
    "                                    'Exif.Photo.MakerNote',\n",
    "                                    'Exif.Canon.DustRemovalData',\n",
    "                                    'Exif.Canon.0x0098',\n",
    "                                    'Exif.Canon.CustomFunctions',\n",
    "                                    'Exif.Canon.SensorInfo',\n",
    "                                    'Exif.Canon.ColorData',\n",
    "                                    'Exif.Canon.0x4002',\n",
    "                                    'Exif.Canon.0x4005',\n",
    "                                    'Exif.Canon.0x4008',\n",
    "                                    'Exif.Canon.0x4009',\n",
    "                                    'Exif.Canon.0x4010',\n",
    "                                    'Exif.Canon.0x4011',\n",
    "                                    'Exif.Canon.0x4012',\n",
    "                                    'Exif.Canon.0x4015',\n",
    "                                    'Exif.Canon.0x4016',\n",
    "                                    'Exif.Canon.0x4017',\n",
    "                                    'Exif.Canon.0x4018',\n",
    "                                    'Exif.Canon.0x4019',\n",
    "                                    'Exif.Photo.UserComment'\n",
    "                                    })\n",
    "\n",
    "def is_useless_str(val):\n",
    "    if not isinstance(val, str):\n",
    "        return False\n",
    "    try:\n",
    "        int(val)\n",
    "        return True # int as string is useless\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return len(val) > 10\n",
    "\n",
    "def convert_value(val):\n",
    "    if isinstance(val, fractions.Fraction):\n",
    "        return float(val)\n",
    "    return val\n",
    "\n",
    "def get_image_metadata(filename):\n",
    "    metadata = pyexiv2.ImageMetadata(filename)\n",
    "    metadata.read()\n",
    "    return { k : convert_value(t.value)\n",
    "            for k, t\n",
    "            in metadata.items()\n",
    "            if not k in IGNORED_IMAGE_METADATA and not is_useless_str(t.value) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get graphical content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_image_content(filename, max_size = 1000):\n",
    "    with open(filename, 'r+') as f:\n",
    "        ext = os.path.splitext(os.path.basename(filename))[1][1:]\n",
    "        with Image(blob = f.read(), format = ext) as img:\n",
    "            vertical = img.size[0] < img.size[1]\n",
    "            if vertical:\n",
    "                width = img.size[0] * max_size / img.size[1]\n",
    "                height = max_size\n",
    "                need_rotate = True\n",
    "            else:\n",
    "                width = max_size\n",
    "                height = img.size[0] * max_size / img.size[1]\n",
    "                need_rotate = False\n",
    "            img.resize(int(width), int(height))\n",
    "            if vertical:\n",
    "                img.rotate(90)\n",
    "            blob = img.make_blob(format='RGB')\n",
    "            pixels = numpy.zeros((width, height, 3))\n",
    "            for col in range(width):\n",
    "                for row in range(height):\n",
    "                    pixel_i = (row * width + col) * 3\n",
    "                    for channel in xrange(3):\n",
    "                        pixels[col, row, channel] = ord(blob[pixel_i + channel]) / 256.0\n",
    "            return pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join all data sources and save data to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALLOWED_IMAGE_EXTENSIONS = ('CR2')\n",
    "OUTCOMES_PREFIX = 'OUTCOMES'\n",
    "META_PREFIX = 'META'\n",
    "IMAGE_CONTENT_FIELD = 'CONTENT'\n",
    "def build_dataframe(in_directory, xmp_parser, max_size = 1000):\n",
    "    result = []\n",
    "    indices = []\n",
    "    for xmp_file in os.listdir(in_directory):\n",
    "        xmp_file = os.path.join(in_directory, xmp_file)\n",
    "        img_file, ext = os.path.splitext(xmp_file)\n",
    "        ext = ext.lower()\n",
    "        if ext != '.xmp' or not os.path.isfile(xmp_file) or not os.path.isfile(img_file):\n",
    "            logger.debug('Skipping %s' % xmp_file)\n",
    "            continue\n",
    "        logger.debug('Processing %s' % xmp_file)\n",
    "        img_res = { '.'.join((OUTCOMES_PREFIX, n)) : v\n",
    "                   for n, v\n",
    "                   in get_xmp_data(xmp_file, xmp_parser).viewitems() }\n",
    "        img_res.update(('.'.join((META_PREFIX, n)), v)\n",
    "                       for n, v\n",
    "                       in get_image_metadata(img_file).viewitems())\n",
    "        img_res[IMAGE_CONTENT_FIELD] = get_image_content(img_file)\n",
    "        result.append(img_res)\n",
    "        indices.append(img_file)\n",
    "    return pandas.DataFrame(data = result, index = indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/filters.js', 'r') as f:\n",
    "    final_filters_info = json.load(f)\n",
    "final_filters_parser = JointParser(final_filters_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "build_dataframe('samples/', final_filters_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
